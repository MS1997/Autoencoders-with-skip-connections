{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NWuT3XOFLBPaQa05nGRz4JsLSLR76Gsw",
      "authorship_tag": "ABX9TyNESbeHhj0YYsQmBsOsBWsS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MS1997/Autoencoders-with-skip-connections/blob/master/Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-JBN9LsF2mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # installing kaggle library to import the data directly into Colab notebook\n",
        " ! pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGb9I5JcF-UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select file containing API key from local system\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYpqwEwNF_KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFc0GJPUGFlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle datasets download -d hsankesara/flickr-image-dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImXaGBa1GI4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzipping the files\n",
        "! unzip flickr-image-dataset.zip -d flickr-image-dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DREQtzT5GOjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, MaxPooling2D, Add, BatchNormalization, LeakyReLU, Reshape, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from random import sample \n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7llpxrb_GT75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.remove('flickr-image-dataset.zip')\n",
        "os.remove('flickr-image-dataset/flickr30k_images/results.csv')\n",
        "list_i = os.listdir('flickr-image-dataset/flickr30k_images/flickr30k_images') #31785\n",
        "len(list_i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDLKEVY-GcPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making directory to store 10k images \n",
        "os.mkdir('flickr-image-dataset/selected')\n",
        "os.mkdir('flickr-image-dataset/selected/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR-BvGvIGfKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's choose 10k random images from the orginal 31k images\n",
        "s_10k = sample(list_i,10000)\n",
        "for i in s_10k:\n",
        "  source = 'flickr-image-dataset/flickr30k_images/flickr30k_images/' + i\n",
        "  destination = 'flickr-image-dataset/selected/train/' + i\n",
        "  os.rename(source, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfoEtO3xGkhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree('flickr-image-dataset/flickr30k_images/flickr30k_images') # removing orginal directory "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOOQv9HJ-9Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('flickr-image-dataset/flickr30k_images/flickr30k_images/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYJTlr1fGlDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=[]\n",
        "# converting the train images to a tensor and standardizing the pixel values\n",
        "for i in os.listdir('flickr-image-dataset/selected/train/'):\n",
        "  image_path = 'flickr-image-dataset/selected/train/' + i\n",
        "  img = load_img(image_path, target_size=(128, 128))\n",
        "  x = img_to_array(img)\n",
        "  x = x.astype('float32')/255.\n",
        "  X_train.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3yq15MvGpZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=np.array(X_train)\n",
        "X_train.shape # (10000, 128, 128, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf3TY0G5xHsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding noise to the training images \n",
        "noise_factor = 0.2\n",
        "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)  \n",
        "X_train_noisy = np.clip(X_train_noisy, 0., 1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncRxKLNLKyyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(128, 128, 3))\n",
        "# Encoder\n",
        "# strides of 2,2 works like max pooling and downsamples the image\n",
        "y = Conv2D(32, (3, 3), padding='same',strides =(2,2))(input_img)\n",
        "y = LeakyReLU()(y)\n",
        "y = Conv2D(64, (3, 3), padding='same',strides =(2,2))(y)\n",
        "y = LeakyReLU()(y)\n",
        "y2 = Conv2D(128, (3, 3), padding='same',strides =(2,2))(y)\n",
        "y = LeakyReLU()(y2)\n",
        "y = Conv2D(256, (3, 3), padding='same',strides =(2,2))(y)\n",
        "y = LeakyReLU()(y)\n",
        "y1 = Conv2D(256, (3, 3), padding='same',strides =(2,2))(y)\n",
        "y = LeakyReLU()(y1)\n",
        "y = Conv2D(512, (3, 3), padding='same',strides =(2,2))(y)\n",
        "y = LeakyReLU()(y)\n",
        "y = Conv2D(1024, (3, 3), padding='same',strides =(2,2))(y)\n",
        "y = LeakyReLU()(y)\n",
        "vol = y.shape # shape of the final convolutional layer\n",
        "x = Flatten()(y)\n",
        "latent = Dense(128,activation='relu')(x) # bottleneck layer to control the information flow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS_Gno0ST-cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function \n",
        "def lrelu_bn(inputs):\n",
        " lrelu = LeakyReLU()(inputs)\n",
        " bn = BatchNormalization()(lrelu)\n",
        " return bn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqWalz0Z-cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoder\n",
        "y = Dense(np.prod(vol[1:]), activation='relu')(latent) # accepting the output from the bottleneck layer\n",
        "y = Reshape((vol[1], vol[2], vol[3]))(y) \n",
        "y = Conv2DTranspose(1024, (3,3), padding='same')(y)\n",
        "y = LeakyReLU()(y)\n",
        "y = Conv2DTranspose(512, (3,3), padding='same',strides=(2,2))(y)\n",
        "y = LeakyReLU()(y)\n",
        "y = Conv2DTranspose(256, (3,3), padding='same',strides=(2,2))(y)\n",
        "y= Add()([y1, y]) # remove to run model without skip connections\n",
        "y = lrelu_bn(y)  # remove to run model without skip connections\n",
        "y = Conv2DTranspose(256, (3,3), padding='same',strides=(2,2))(y)\n",
        "y = LeakyReLU()(y) \n",
        "y = Conv2DTranspose(128, (3,3), padding='same',strides=(2,2))(y)   \n",
        "y= Add()([y2, y]) # remove to run model without skip connections\n",
        "y = lrelu_bn(y) # remove to run model without skip connections\n",
        "y = Conv2DTranspose(64, (3,3), padding='same',strides=(2,2))(y)\n",
        "y = LeakyReLU()(y)\n",
        "y = Conv2DTranspose(32, (3,3), padding='same',strides=(2,2))(y)\n",
        "y = LeakyReLU()(y)\n",
        "y = Conv2DTranspose(3, (3,3), activation='sigmoid', padding='same',strides=(2,2))(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79rapPdQaEaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = Model(input_img,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usPuFwE8aH96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xs90fOVaMmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.compile(optimizer=Adam(0.001,beta_1=0.9), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "history_2 = model_1.fit(X_train_noisy,X_train,batch_size = 32,epochs = 200,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t3Pb2SrjGDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the train and validation loss\n",
        "plt.plot(history_2.history['loss']) \n",
        "plt.plot(history_2.history['val_loss'])\n",
        "plt.title('Comparison of Train & Validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjjwAxmgjh-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WayjeAntjroD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving model weights\n",
        "model_1.save_weights(\"/content/gdrive/My Drive/model_1.h5\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alXe4vaObRLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preddiction on train images\n",
        "preds= model_1.predict(X_train_noisy[0:4,:,:,:]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwGQ5ldMbfod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_noisy.shape # (10000, 128, 128, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuTjSTsHbWW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(preds[1].reshape(128, 128,3)) # denoised image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwkkimRK0LpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X_train[1].reshape(128, 128,3)) # orginal image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4iE0zMP0PtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X_train_noisy[2].reshape(128, 128,3)) # image with noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0TUXi6EngVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.load_weights('/content/gdrive/My Drive/model_2.h5') #load the previously saved weights \n",
        "# before running this the model defining block of code should be run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJmy7JQIbxuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the test image\n",
        "from io import BytesIO\n",
        "from google.colab import files\n",
        "#uploading the image for 'content'\n",
        "uploaded = files.upload()\n",
        "content = Image.open(BytesIO(uploaded['columbia.jpg']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLLr5EZhcAxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting the test image to a tensor and adding noise \n",
        "img = load_img(\"columbia.jpg\", target_size=(128, 128)) #\n",
        "x = img_to_array(img)\n",
        "x = x.astype('float32')/255.\n",
        "noise_factor = 0.2\n",
        "x_noisy = x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x.shape)  \n",
        "x_noisy = np.clip(x_noisy, 0., 1.)\n",
        "x_noisy = np.expand_dims(x_noisy, axis=0)\n",
        "x = np.expand_dims(x, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdsl4ubFk4QV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x.reshape(128, 128,3)) # orginal test image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avFmZM4X_hFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x_noisy.reshape(128, 128,3)) # test image with noise "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfUDOAANcMQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds= model_1.predict(x_noisy)  # image reconstruction on test image with noise\n",
        "plt.imshow(test_preds.reshape(128, 128,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBsVSTdCSU_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install keract # install keract package to see actiavtion outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgeETl72VDVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmWSeggKVGul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act = keract.get_activations(model_1,x) # function to get activation outputs of the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ErFE_gQVkjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keract.display_activations(act) # function to display activation outputs of the model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}